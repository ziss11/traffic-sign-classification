{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrafficSignClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1O25nkrPsQH0CBMNOOegzuEisH1r1hVmh",
      "authorship_tag": "ABX9TyPk+u73/TJaI6lXuWeheRtJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "Dm9kopQmzDT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LY0cZPT517_V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import matplotlib\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from google.colab import files\n",
        "from keras import layers\n",
        "from keras.models import Sequential, load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(train_path, test_path):\n",
        "  with open(train_path, mode='rb') as f:\n",
        "    train = pickle.load(f)\n",
        "  \n",
        "  with open(test_path, mode='rb') as f:\n",
        "    test = pickle.load(f)\n",
        "      \n",
        "  print(\"Data loaded\")\n",
        "\n",
        "  return train, test"
      ],
      "metadata": {
        "id": "q4Zk0wAnw2rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_file = \"/content/drive/MyDrive/Colab Notebooks/DicodingMLTerapan/Datasets/GermanTrafficSign/train.p\"\n",
        "testing_file = \"/content/drive/MyDrive/Colab Notebooks/DicodingMLTerapan/Datasets/GermanTrafficSign/test.p\" \n",
        "\n",
        "train, test = load_data(training_file, testing_file)"
      ],
      "metadata": {
        "id": "XQ4OvoA1xoT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signs_name_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DicodingMLTerapan/Datasets/GermanTrafficSign/signnames.csv')\n",
        "signs_name_df.head()"
      ],
      "metadata": {
        "id": "uueK4NQC0RVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sign_name = signs_name_df.SignName.values\n",
        "sign_name"
      ],
      "metadata": {
        "id": "NFUZL8U7010a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = train['features'], train['labels']\n",
        "\n",
        "data = np.array(X)\n",
        "labels = np.array(y)\n",
        "\n",
        "print(data.shape, labels.shape)\n",
        "\n",
        "X_test, y_test = test['features'], test['labels']\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "rPXUCxV_1KJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    data, labels, test_size=.1, random_state=0)\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "cOfEuPTN23P0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_labels = np.unique(y_train).size\n",
        "\n",
        "def hist_data(y_data, title=None, ax=None, **kwargs):\n",
        "    if not ax :\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111)\n",
        "    ax.hist(y_data, np.arange(-0.5, n_labels+1.5), stacked=True, **kwargs)\n",
        "    ax.set_xlim(-0.5, n_labels-0.5)\n",
        "    if 'label' in kwargs : ax.legend()\n",
        "    if title : ax.set_title(title)\n",
        "        \n",
        "fig, ax = plt.subplots(1,3, figsize=(18,5))\n",
        "hist_data(y_train, title='Distribusi kelas pada data training', ax=ax[0])\n",
        "hist_data(y_val, title='Distribusi kelas pada data validasi', ax=ax[1], color='black')\n",
        "hist_data(y_test, title='Distribusi kelas pada data test', ax=ax[2], color='grey')"
      ],
      "metadata": {
        "id": "Etm8b0J54JYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train, n_labels)\n",
        "y_val = to_categorical(y_val, n_labels)"
      ],
      "metadata": {
        "id": "MCg3ZW054k1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs['acc'] >= 0.96):\n",
        "      print('\\nAkurasi telah mencapai 96%, Stop training!')\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callback = MyCallback()"
      ],
      "metadata": {
        "id": "dtgq-bg2DyCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(n_classes):\n",
        "  model = Sequential()\n",
        "  # CNN layer 1\n",
        "  model.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=X_train.shape[1:]))\n",
        "  model.add(layers.Conv2D(32, (5, 5), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(2, 2))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  # CNN layer 2\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(2, 2))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  ## Fully Connected layer\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Dense(n_classes, activation='softmax'))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "wOFuuuV86sqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 25\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "model = build_model(n_labels)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "0ymwsDAv-hXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=32,\n",
        "    epochs=epoch,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[callback],\n",
        "    verbose=1\n",
        "  )"
      ],
      "metadata": {
        "id": "WcCevM9_-6zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot graph for accuracy\n",
        "plt.plot(hist.history['acc'], label='Training Accuracy')\n",
        "plt.plot(hist.history['val_acc'], label='Val Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot graph for loss\n",
        "plt.plot(hist.history['loss'], label='Training Loss')\n",
        "plt.plot(hist.history['val_loss'], label='Val Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cXSdSwGhCqf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "accuracy_score(y_test, pred)"
      ],
      "metadata": {
        "id": "xK_h3LI3FV6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "M6LxorWBFy7N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}